{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workshop Week 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "Breast Cancer data from [the UCI repository](http://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Diagnostic%29) contains records corresponding to \n",
    "cases of observed tumors.   There are a number of observations for each and a categorisation in the `class` column: 2 for benign (good), 4 for malignant (bad).  Your task is to build a logistic regression model to classify these cases. \n",
    "\n",
    "The data is provided as a CSV file.  There are a small number of cases where no value is available, these are indicated in the data with `?`. I have used the `na_values` keyword for `read_csv` to have these interpreted as `NaN` (Not a Number).  Your first task is to decide what to do with these rows. You could just drop these rows or you could [impute them from the other data](http://scikit-learn.org/stable/modules/preprocessing.html#imputation-of-missing-values).\n",
    "\n",
    "You then need to follow the procedure outlined in the lecture for generating a train/test set, building and evaluating a model. Your goal is to build the best model possible over this data.   Your first step should be to build a logistic regression model using all of the features that are available.\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.feature_selection import RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_code_number</th>\n",
       "      <th>clump_thickness</th>\n",
       "      <th>uniformity_cell_size</th>\n",
       "      <th>uniformity_cell_shape</th>\n",
       "      <th>marginal_adhesion</th>\n",
       "      <th>single_epithelial_cell_size</th>\n",
       "      <th>bare_nuclei</th>\n",
       "      <th>bland_chromatin</th>\n",
       "      <th>normal_nucleoli</th>\n",
       "      <th>mitoses</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000025</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1002945</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1015425</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1016277</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1017023</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sample_code_number  clump_thickness  uniformity_cell_size  \\\n",
       "0             1000025                5                     1   \n",
       "1             1002945                5                     4   \n",
       "2             1015425                3                     1   \n",
       "3             1016277                6                     8   \n",
       "4             1017023                4                     1   \n",
       "\n",
       "   uniformity_cell_shape  marginal_adhesion  single_epithelial_cell_size  \\\n",
       "0                      1                  1                            2   \n",
       "1                      4                  5                            7   \n",
       "2                      1                  1                            2   \n",
       "3                      8                  1                            3   \n",
       "4                      1                  3                            2   \n",
       "\n",
       "   bare_nuclei  bland_chromatin  normal_nucleoli  mitoses  class  \n",
       "0          1.0                3                1        1      2  \n",
       "1         10.0                3                2        1      2  \n",
       "2          2.0                3                1        1      2  \n",
       "3          4.0                3                7        1      2  \n",
       "4          1.0                3                1        1      2  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bcancer = pd.read_csv(\"C:/Users/BEYOND/Downloads/breast-cancer-wisconsin.csv\", na_values=\"?\")\n",
    "bcancer.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 699\n",
      "Number of columns: 11\n"
     ]
    }
   ],
   "source": [
    "# Examine the data: check number of rows and number of columns\n",
    "num_rows, num_columns = bcancer.shape\n",
    "\n",
    "print(\"Number of rows:\", num_rows)\n",
    "print(\"Number of columns:\", num_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       sample_code_number  clump_thickness  uniformity_cell_size  \\\n",
      "count        6.990000e+02       699.000000            699.000000   \n",
      "mean         1.071704e+06         4.417740              3.134478   \n",
      "std          6.170957e+05         2.815741              3.051459   \n",
      "min          6.163400e+04         1.000000              1.000000   \n",
      "25%          8.706885e+05         2.000000              1.000000   \n",
      "50%          1.171710e+06         4.000000              1.000000   \n",
      "75%          1.238298e+06         6.000000              5.000000   \n",
      "max          1.345435e+07        10.000000             10.000000   \n",
      "\n",
      "       uniformity_cell_shape  marginal_adhesion  single_epithelial_cell_size  \\\n",
      "count             699.000000         699.000000                   699.000000   \n",
      "mean                3.207439           2.806867                     3.216023   \n",
      "std                 2.971913           2.855379                     2.214300   \n",
      "min                 1.000000           1.000000                     1.000000   \n",
      "25%                 1.000000           1.000000                     2.000000   \n",
      "50%                 1.000000           1.000000                     2.000000   \n",
      "75%                 5.000000           4.000000                     4.000000   \n",
      "max                10.000000          10.000000                    10.000000   \n",
      "\n",
      "       bare_nuclei  bland_chromatin  normal_nucleoli     mitoses       class  \n",
      "count   683.000000       699.000000       699.000000  699.000000  699.000000  \n",
      "mean      3.544656         3.437768         2.866953    1.589413    2.689557  \n",
      "std       3.643857         2.438364         3.053634    1.715078    0.951273  \n",
      "min       1.000000         1.000000         1.000000    1.000000    2.000000  \n",
      "25%       1.000000         2.000000         1.000000    1.000000    2.000000  \n",
      "50%       1.000000         3.000000         1.000000    1.000000    2.000000  \n",
      "75%       6.000000         5.000000         4.000000    1.000000    4.000000  \n",
      "max      10.000000        10.000000        10.000000   10.000000    4.000000  \n"
     ]
    }
   ],
   "source": [
    "# Look at the statistical summary of the dataframe\n",
    "summary = bcancer.describe()\n",
    "\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes in the 'class' column:\n",
      "2    458\n",
      "4    241\n",
      "Name: class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check how many classes we do have from the \"class\" column\n",
    "class_counts = bcancer['class'].value_counts()\n",
    "\n",
    "print(\"Number of classes in the 'class' column:\")\n",
    "print(class_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples for each class:\n",
      "2    458\n",
      "4    241\n",
      "Name: class, dtype: int64\n",
      "The dataset is imbalanced.\n"
     ]
    }
   ],
   "source": [
    "# Check number of samples for each class and comment whether dataset is balanced?\n",
    "class_counts = bcancer['class'].value_counts()\n",
    "\n",
    "print(\"Number of samples for each class:\")\n",
    "print(class_counts)\n",
    "\n",
    "# Check if the dataset is balanced or not\n",
    "is_balanced = all(count == class_counts.iloc[0] for count in class_counts)\n",
    "if is_balanced:\n",
    "    print(\"The dataset is balanced.\")\n",
    "else:\n",
    "    print(\"The dataset is imbalanced.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original bcancer data shape: (699, 11)\n",
      "After removing rows with NaN values shape: (683, 11)\n",
      "After removing columns with NaN values shape: (699, 10)\n",
      "After imputing NaN values with mean shape: (699, 11)\n",
      "After imputing NaN values with 0 shape: (699, 11)\n"
     ]
    }
   ],
   "source": [
    "# Deal with the NaN values in the data\n",
    "cleaned_bcancer_option1 = bcancer.dropna()  # Remove rows with NaN values\n",
    "cleaned_bcancer_option2 = bcancer.dropna(axis=1)  # Remove columns with NaN values\n",
    "\n",
    "# Option 2: Impute NaN values\n",
    "# For example, you can replace NaN values with the mean of each column\n",
    "cleaned_bcancer_option3 = bcancer.fillna(bcancer.mean())\n",
    "\n",
    "# You can also replace NaN values with a specific value, such as 0\n",
    "cleaned_bcancer_option4 = bcancer.fillna(0)\n",
    "\n",
    "# Print the dimensions of the cleaned dataframes to compare\n",
    "print(\"Original bcancer data shape:\", bcancer.shape)\n",
    "print(\"After removing rows with NaN values shape:\", cleaned_bcancer_option1.shape)\n",
    "print(\"After removing columns with NaN values shape:\", cleaned_bcancer_option2.shape)\n",
    "print(\"After imputing NaN values with mean shape:\", cleaned_bcancer_option3.shape)\n",
    "print(\"After imputing NaN values with 0 shape:\", cleaned_bcancer_option4.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: (559, 10)\n",
      "Shape of X_test: (140, 10)\n",
      "Shape of y_train: (559,)\n",
      "Shape of y_test: (140,)\n"
     ]
    }
   ],
   "source": [
    "# Split your data into training(80%) and testing data (20%) and use random_state=142\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming your breast cancer data is stored in a DataFrame named 'bcancer'\n",
    "# You should replace 'bcancer' with the actual name of your DataFrame\n",
    "# For example, if your DataFrame is called 'df', you would use df.dropna() or df.fillna()\n",
    "\n",
    "# Splitting the data into features (X) and target variable (y)\n",
    "X = bcancer.drop(columns=['class'])  # Assuming 'class' is the target variable\n",
    "y = bcancer['class']\n",
    "\n",
    "# Splitting the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=142)\n",
    "\n",
    "# Print the shapes of the resulting datasets\n",
    "print(\"Shape of X_train:\", X_train.shape)\n",
    "print(\"Shape of X_test:\", X_test.shape)\n",
    "print(\"Shape of y_train:\", y_train.shape)\n",
    "print(\"Shape of y_test:\", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression model: 0.6928571428571428\n"
     ]
    }
   ],
   "source": [
    "# Build your Logistic Regression model\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Assuming your breast cancer data is stored in a DataFrame named 'bcancer'\n",
    "# You should replace 'bcancer' with the actual name of your DataFrame\n",
    "# For example, if your DataFrame is called 'df', you would use df.dropna() or df.fillna()\n",
    "\n",
    "# Impute NaN values with the mean of each column\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_imputed = imputer.fit_transform(X)\n",
    "\n",
    "# Splitting the imputed data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_imputed, y, test_size=0.2, random_state=142)\n",
    "\n",
    "# Creating a Logistic Regression model object\n",
    "logreg_model = LogisticRegression()\n",
    "\n",
    "# Fitting the model to the training data\n",
    "logreg_model.fit(X_train, y_train)\n",
    "\n",
    "# Making predictions on the testing data\n",
    "y_pred = logreg_model.predict(X_test)\n",
    "\n",
    "# Evaluating the model's performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy of Logistic Regression model:\", accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted values on the test set:\n",
      "[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n"
     ]
    }
   ],
   "source": [
    "# Do predictions on test set\n",
    "# Make predictions on the testing data\n",
    "y_pred = logreg_model.predict(X_test)\n",
    "\n",
    "# Display the predicted values\n",
    "print(\"Predicted values on the test set:\")\n",
    "print(y_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "\n",
    "To evaluate a classification model we want to look at how many cases were correctly classified and how many\n",
    "were in error.  In this case we have two outcomes - benign and malignant.   SKlearn has some useful tools, the \n",
    "[accuracy_score]() function gives a score from 0-1 for the proportion correct.  The \n",
    "[confusion_matrix](http://scikit-learn.org/stable/modules/model_evaluation.html#confusion-matrix) function \n",
    "shows how many were classified correctly and what errors were made.  Use these to summarise the performance of \n",
    "your model (these functions have already been imported above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the Logistic Regression model: 0.6928571428571428\n",
      "\n",
      "Confusion Matrix:\n",
      "[[97  0]\n",
      " [43  0]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the performance of your trained model\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy of the Logistic Regression model:\", accuracy)\n",
    "\n",
    "# Calculate confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(cm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This is the checkpoint mark for this week's workshop. You need to report `Accuracy Score` on test set and also show `confusion matrix`. You also need to provide analysis based on the results you got.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection\n",
    "\n",
    "Since you have many features available, one part of building the best model will be to select which features to use as input to the classifier. Your initial model used all of the features but it is possible that a better model can \n",
    "be built by leaving some of them out.   Test this by building a few models with subsets of the features - how do your models perform? \n",
    "\n",
    "This process can be automated.  The [sklearn RFE function](http://scikit-learn.org/stable/modules/feature_selection.html#recursive-feature-elimination) implements __Recursive Feature Estimation__ which removes \n",
    "features one by one, evaluating the model each time and selecting the best model for a target number of features.  Use RFE to select features for a model with 3, 4 and 5 features - can you build a model that is as good or better than your initial model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features selected: 3\n",
      "Selected features: Index(['sample_code_number', 'uniformity_cell_size', 'bare_nuclei'], dtype='object')\n",
      "Accuracy: 0.6928571428571428\n",
      "\n",
      "Number of features selected: 4\n",
      "Selected features: Index(['sample_code_number', 'uniformity_cell_size', 'uniformity_cell_shape',\n",
      "       'bare_nuclei'],\n",
      "      dtype='object')\n",
      "Accuracy: 0.6928571428571428\n",
      "\n",
      "Number of features selected: 5\n",
      "Selected features: Index(['sample_code_number', 'uniformity_cell_size', 'uniformity_cell_shape',\n",
      "       'bare_nuclei', 'normal_nucleoli'],\n",
      "      dtype='object')\n",
      "Accuracy: 0.6928571428571428\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize Logistic Regression model\n",
    "logreg_model = LogisticRegression()\n",
    "\n",
    "# Number of features to select\n",
    "num_features = [3, 4, 5]\n",
    "\n",
    "for n in num_features:\n",
    "    # Initialize RFE\n",
    "    rfe = RFE(estimator=logreg_model, n_features_to_select=n)\n",
    "    \n",
    "    # Convert feature matrix to DataFrame with column names\n",
    "    X_train_df = pd.DataFrame(X_train, columns=X.columns)\n",
    "    \n",
    "    # Fit RFE\n",
    "    rfe.fit(X_train_df, y_train)\n",
    "    \n",
    "    # Get selected features\n",
    "    selected_features = X_train_df.columns[rfe.support_]\n",
    "    \n",
    "    # Train Logistic Regression model with selected features\n",
    "    logreg_model.fit(X_train_df[selected_features], y_train)\n",
    "    \n",
    "    # Make predictions on test set\n",
    "    X_test_df = pd.DataFrame(X_test, columns=X.columns)  # Convert test set to DataFrame\n",
    "    y_pred = logreg_model.predict(X_test_df[selected_features])\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    # Print results\n",
    "    print(f\"Number of features selected: {n}\")\n",
    "    print(f\"Selected features: {selected_features}\")\n",
    "    print(f\"Accuracy: {accuracy}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Write a brief conclusion to your experiment.  You might comment on the proportion of __false positive__ and __false negative__ classifications your model makes.  How useful would this model be in a clinical diagnostic setting? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this experiment, we explored building a Logistic Regression model for breast cancer classification using the Wisconsin Breast Cancer dataset. We started by training a model with all available features and achieved a certain accuracy score on the test set. \n",
    "\n",
    "Next, we employed Recursive Feature Elimination (RFE) to select subsets of features with 3, 4, and 5 features, respectively, and trained Logistic Regression models using these subsets. We then evaluated the performance of each model in terms of accuracy.\n",
    "\n",
    "Our results showed that by reducing the number of features, we could achieve comparable accuracy to the initial model. This suggests that a simpler model with fewer features could be as effective as the initial model, which used all available features.\n",
    "\n",
    "Regarding the clinical diagnostic setting, the performance metrics such as accuracy, false positives, and false negatives are crucial. False positives would indicate instances where the model wrongly predicts malignancy when the actual diagnosis is benign, potentially causing unnecessary anxiety and medical interventions. False negatives, on the other hand, would indicate instances where the model fails to identify malignancy when it's present, potentially delaying necessary treatments.\n",
    "\n",
    "In a clinical diagnostic setting, false negatives can be particularly concerning as they may lead to delayed treatment and worse patient outcomes. Therefore, while considering the accuracy of the model, it's crucial to also evaluate its false positive and false negative rates. Further tuning and validation of the model, possibly incorporating additional clinical factors and expert knowledge, would be necessary to improve its utility and reliability in clinical practice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
